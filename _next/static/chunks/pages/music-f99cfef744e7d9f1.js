(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[817],{6790:(e,s,a)=>{"use strict";a.d(s,{A:()=>i});var t=a(7876);a(4232);var l=a(8230),n=a.n(l);function i(){return(0,t.jsx)("div",{className:"flex flex-col items-center justify-center text-black text-center",children:(0,t.jsxs)("nav",{className:"p-8 flex flex-wrap justify-center gap-x-8 gap-y-4 max-w-6xl px-4",children:[(0,t.jsx)(n(),{href:"/",className:"text-lg text-black hover:underline",children:"Home"}),(0,t.jsx)(n(),{href:"/bio",className:"text-lg text-black hover:underline",children:"About me"}),(0,t.jsx)(n(),{href:"/symbiosiso",className:"text-lg text-accent hover:underline",children:"Reactive Textiles"}),(0,t.jsx)(n(),{href:"/robotic_fish",className:"text-lg text-accent hover:underline",children:"Robotic Fish"}),(0,t.jsx)(n(),{href:"/heatit",className:"text-lg text-accent hover:underline",children:"Heatit\xb0C"}),(0,t.jsx)(n(),{href:"/interactive",className:"text-lg text-accent hover:underline",children:"Interactive"}),(0,t.jsx)(n(),{href:"/music",className:"text-lg text-accent hover:underline",children:"Music"}),(0,t.jsx)(n(),{href:"https://wearnotch.com",className:"text-lg text-accent hover:underline",children:"Notch Motion Sensors"})]})})}},7404:(e,s,a)=>{"use strict";a.r(s),a.d(s,{default:()=>o});var t=a(7876);a(4232);var l=a(8230),n=a.n(l),i=a(4587),c=a.n(i),r=a(6790);function o(){return(0,t.jsxs)("div",{className:"min-h-screen bg-background-light text-black",children:[(0,t.jsx)(r.A,{}),(0,t.jsx)("div",{className:"flex flex-col items-center justify-center text-center px-8 pt-8 pb-32",children:(0,t.jsxs)("div",{className:"max-w-3xl text-left space-y-8",children:[(0,t.jsxs)("div",{className:"space-y-4",children:[(0,t.jsx)("h1",{className:"text-5xl font-bold mb-12",children:"Neurime"}),(0,t.jsx)("h2",{className:"text-2xl font-semibold mb-4",children:"A Neural Network-Inspired Musical Interface"}),(0,t.jsx)("p",{className:"text-xl leading-normal text-gray-700 font-semibold",children:"An instrument that learns, evolves, and composes with you"})]}),(0,t.jsx)("div",{className:"w-full aspect-video rounded-lg overflow-hidden",children:(0,t.jsx)("iframe",{title:"vimeo-player",src:"https://player.vimeo.com/video/50642688?h=45394778e6",width:"640",height:"360",frameborder:"0",allowfullscreen:!0})}),(0,t.jsxs)("div",{className:"space-y-4",children:[(0,t.jsx)("h2",{className:"text-3xl font-bold mb-8 text-accent",children:"What is Neurime?"}),(0,t.jsx)("p",{className:"text-xl leading-normal text-gray-700",children:"Neurime is a large-scale interactive musical instrument inspired by neural networks. Designed in collaboration with Michael Rosen at NYU ITP, it reimagines musical composition as an adaptive system where connections form, evolve, and fade—just like synapses in the brain."})]}),(0,t.jsxs)("div",{className:"space-y-4",children:[(0,t.jsx)("h2",{className:"text-3xl font-bold mb-8 text-accent",children:"How It Works"}),(0,t.jsx)("div",{className:"space-y-4",children:(0,t.jsx)("div",{className:"flex justify-start mb-6",children:(0,t.jsx)(c(),{src:"/images/neurime/neurime.jpg",alt:"SymbiosisW Wall Installation",width:800,height:400,className:"rounded-lg object-cover w-full"})})}),(0,t.jsx)("p",{className:"text-xl leading-normal text-gray-700",children:'Each "neuron" in Neurime is represented by an individual audio channel that changes in complexity with use. The more frequently a node is activated, the richer its resonance becomes through additive synthesis and modulation.'}),(0,t.jsxs)("p",{className:"text-xl leading-normal text-gray-700",children:[(0,t.jsx)("span",{className:"font-semibold",children:"The Neural Connection:"})," When two or more nodes are activated together, a connection is formed. Neurime remembers these interactions, indexing the relationships by strength and distance. Over time, a dynamic web of musical connections emerges, allowing users to compose by touch."]}),(0,t.jsxs)("div",{className:"bg-white rounded-lg p-6 shadow-sm mt-8",children:[(0,t.jsx)("h3",{className:"text-2xl font-bold mb-4 text-accent",children:"Memory & Evolution:"}),(0,t.jsxs)("ul",{className:"list-none space-y-2",children:[(0,t.jsxs)("li",{className:"text-xl leading-normal text-gray-700",children:[(0,t.jsx)("span",{className:"text-accent",children:"•"})," Holding a neuron stores rhythmic patterns dynamically."]}),(0,t.jsxs)("li",{className:"text-xl leading-normal text-gray-700",children:[(0,t.jsx)("span",{className:"text-accent",children:"•"})," Repeating the action recalls the stored pattern and plays it back."]}),(0,t.jsxs)("li",{className:"text-xl leading-normal text-gray-700",children:[(0,t.jsx)("span",{className:"text-accent",children:"•"})," Connections gradually fade, ensuring that compositions continuously evolve."]})]})]}),(0,t.jsx)("p",{className:"text-xl leading-normal text-gray-700",children:"This real-time learning system allows people interacting with Neurime to create ever-changing soundscapes, forming music collaboratively and intuitively."})]}),(0,t.jsxs)("div",{className:"space-y-4",children:[(0,t.jsx)("h2",{className:"text-3xl font-bold mb-8 text-accent",children:"Why We Built It"}),(0,t.jsx)("div",{className:"flex justify-start mb-6",children:(0,t.jsx)(c(),{src:"/images/neurime/neurime2.png",alt:"Neurime 2",width:800,height:400,className:"rounded-lg object-cover w-full"})}),(0,t.jsx)("p",{className:"text-xl leading-normal text-gray-700",children:"The goal was to create an audio interface that behaves like a neural network—where connections are formed through touch and sound spreads across the system. By interacting with the wall-based installation, users could compose music organically, shaping the auditory landscape by triggering nodes and establishing temporary sound relationships."})]}),(0,t.jsxs)("div",{className:"space-y-4",children:[(0,t.jsx)("h2",{className:"text-3xl font-bold mb-8 text-accent",children:"Exhibitions & Performances"}),(0,t.jsx)("div",{className:"w-full aspect-video rounded-lg overflow-hidden",children:(0,t.jsx)("iframe",{src:"https://player.vimeo.com/video/33837689?badge=0&autopause=0&player_id=0&app_id=58479",title:"Neurime - Neural Interfaces for Musical Expression",allow:"autoplay; fullscreen; picture-in-picture",allowFullScreen:!0,className:"w-full h-full"})}),(0,t.jsxs)("ul",{className:"list-none space-y-2",children:[(0,t.jsxs)("li",{className:"text-xl leading-normal text-gray-700",children:[(0,t.jsx)("span",{className:"text-accent",children:"•"})," Neurhyme, Cameo Gallery, Brooklyn (2011)"]}),(0,t.jsxs)("li",{className:"text-xl leading-normal text-gray-700",children:[(0,t.jsx)("span",{className:"text-accent",children:"•"})," New Interfaces for Musical Expression (NIME), Michigan (2012)"]})]})]}),(0,t.jsxs)("div",{className:"space-y-4",children:[(0,t.jsx)("h2",{className:"text-3xl font-bold mb-8 text-accent",children:"Exploring the Future of Interactive Sound"}),(0,t.jsx)("div",{className:"flex justify-start mb-6",children:(0,t.jsx)(c(),{src:"/images/neurime/neurime3.jpg",alt:"Large Scale Wall Installation",width:800,height:400,className:"rounded-lg object-cover w-full"})}),(0,t.jsx)("p",{className:"text-xl leading-normal text-gray-700",children:"Neurime was an exploration into how AI-inspired systems can influence musical expression. It remains a fascinating study of adaptive, evolving compositions—where music is not just played, but learns and changes with the performer."})]})]})}),(0,t.jsxs)("nav",{className:"p-8 flex space-x-6 justify-center",children:[(0,t.jsx)(n(),{href:"/",className:"text-accent hover:underline",children:"Back to Home"}),(0,t.jsx)(n(),{href:"/projects",className:"text-accent hover:underline",children:"Projects"})]})]})}},8258:(e,s,a)=>{(window.__NEXT_P=window.__NEXT_P||[]).push(["/music",function(){return a(7404)}])}},e=>{var s=s=>e(e.s=s);e.O(0,[230,587,636,593,792],()=>s(8258)),_N_E=e.O()}]);